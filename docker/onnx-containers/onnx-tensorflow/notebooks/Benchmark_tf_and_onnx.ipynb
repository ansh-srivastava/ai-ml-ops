{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Pre-trained Models from Tensorflow to ONNX\n",
    "\n",
    "[**MODEL ZOO**](https://modelzoo.co/)\n",
    "\n",
    "Tensorflow has a large selection of pre-trained ssd models in its [object detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md).\n",
    "\n",
    "ONNX has its [own model zoo](https://github.com/winnerineast/models-onnx)\n",
    "\n",
    "This tutorial shows how to convert them to ONNX and run them under [onnxruntime](https://github.com/microsoft/onnxruntime).\n",
    "\n",
    "\n",
    "We use [ssd_mobilenet_v1_coco](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz) as example in this tutorial. Other models should work as well.\n",
    "\n",
    "ONNX has support for various ops needed for SSD models since opset-10 so you'll need to use onnx-1.5 or better and a runtime that supports opset-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:32.808718Z",
     "start_time": "2020-04-27T05:33:30.795241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Python 3.7.7\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade ipymagic -q\n",
    "#import ipymagic\n",
    "%load_ext ipymagic\n",
    "\n",
    "%python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:34.800652Z",
     "start_time": "2020-04-27T05:33:32.815572Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import onnx\n",
    "import tf2onnx\n",
    "import onnxmltools\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Environment\n",
    "Before we start, lets setup some variables where to find things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:34.813377Z",
     "start_time": "2020-04-27T05:33:34.809170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For this tutorial use used the following versions:\n",
      "\n",
      "python      : 3.7.7\n",
      "numpy       : 1.16.0\n",
      "tensorflow  : 1.15.2\n",
      "onnx        : 1.6.0\n",
      "tf2onnx     : 1.5.6\n",
      "onnxmltools : 1.6.1\n",
      "onnxruntime : 1.1.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "For this tutorial use used the following versions:\n",
    "\n",
    "python      : {sys.version.split(' ')[0]}\n",
    "numpy       : {np.__version__}\n",
    "tensorflow  : {tf.__version__}\n",
    "onnx        : {onnx.__version__}\n",
    "tf2onnx     : {tf2onnx.__version__}\n",
    "onnxmltools : {onnxmltools.__version__}\n",
    "onnxruntime : {onnxruntime.__version__}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:35.523933Z",
     "start_time": "2020-04-27T05:33:34.814604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmake version 3.14.0\r\n",
      "\r\n",
      "CMake suite maintained and supported by Kitware (kitware.com/cmake).\r\n"
     ]
    }
   ],
   "source": [
    "# For onnx build\n",
    "!cmake --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:35.624526Z",
     "start_time": "2020-04-27T05:33:35.529699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'PATH': '/opt/conda/envs/onnx-tf1-15/bin:/opt/conda/bin:/opt/conda/bin:/opt/conda/sbin:/opt/conda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
       "        'HOSTNAME': '421dbd2efbbe',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CONDA_PATH': '/opt/conda',\n",
       "        'JUPYTER_CONFIG_DIR': '/opt/conda/etc/jupyter',\n",
       "        'JUPYTER_DATA_DIR': '/opt/conda/share/jupyter',\n",
       "        'JAVA_HOME': '/usr/lib/jvm/default-java',\n",
       "        'WORKDIR': '/workspace',\n",
       "        'HOME': '/root',\n",
       "        'LC_CTYPE': 'C.UTF-8',\n",
       "        'KERNEL_LAUNCH_TIMEOUT': '40',\n",
       "        'PYTHONPATH': '/opt/conda/envs/onnx-tf1-15/bin/python',\n",
       "        'JPY_PARENT_PID': '1',\n",
       "        'CLICOLOR': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:35.704414Z",
     "start_time": "2020-04-27T05:33:35.625617Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = os.environ['WORKDIR']  # '/workspace'\n",
    "WORK = os.path.join(ROOT, \"trained_models\")\n",
    "os.environ['WORK'] = WORK\n",
    "\n",
    "os.makedirs(WORK, exist_ok=True)\n",
    "\n",
    "# Enforce `tf2onnx` to CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Benchmark: `tf`, `tf2onnx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:45:49.234035Z",
     "start_time": "2020-04-27T05:45:49.227724Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = \"resnet50\"\n",
    "\n",
    "os.environ['MODEL'] = MODEL\n",
    "MODEL_PATH = os.path.join(WORK, MODEL)\n",
    "os.environ['MODEL_PATH'] = MODEL_PATH\n",
    "os.environ['MODEL_PATH_TF'] = MODEL_PATH_TF = os.path.join(MODEL_PATH, 'tf', MODEL)\n",
    "os.environ['MODEL_PATH_H5'] = MODEL_PATH_H5 = os.path.join(MODEL_PATH, 'h5', MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:39.187931Z",
     "start_time": "2020-04-27T05:33:38.845600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/trained_models/resnet50\r\n",
      "├── h5\r\n",
      "│   └── resnet50.h5\r\n",
      "└── tf\r\n",
      "    └── resnet50\r\n",
      "        ├── assets\r\n",
      "        ├── onnx_model\r\n",
      "        │   └── from_frozen_with_keras2onnx.onnx\r\n",
      "        ├── saved_model.pb\r\n",
      "        └── variables\r\n",
      "            ├── variables.data-00000-of-00002\r\n",
      "            ├── variables.data-00001-of-00002\r\n",
      "            └── variables.index\r\n",
      "\r\n",
      "6 directories, 6 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree $MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:59.777491Z",
     "start_time": "2020-04-27T05:33:42.938460Z"
    }
   },
   "outputs": [],
   "source": [
    "!curl -fsSL http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz | tar zxf -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:33:59.857966Z",
     "start_time": "2020-04-27T05:33:59.801218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['101_ObjectCategories/revolver/image_0077.jpg',\n",
       " '101_ObjectCategories/revolver/image_0053.jpg',\n",
       " '101_ObjectCategories/revolver/image_0030.jpg',\n",
       " '101_ObjectCategories/revolver/image_0027.jpg',\n",
       " '101_ObjectCategories/revolver/image_0070.jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paths = glob(\"101_ObjectCategories/*[!BACKGROUND_Google]/*.jpg\")\n",
    "print(len(data_paths))\n",
    "data_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN `tf_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:34:05.093543Z",
     "start_time": "2020-04-27T05:34:05.088409Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['TF_MODEL_PATH'] = TF_MODEL_PATH = os.path.join(\n",
    "    os.environ['MODEL_PATH_TF'],\n",
    "    'saved_model.pb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:34:13.147829Z",
     "start_time": "2020-04-27T05:34:06.445692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "tf_model = tf.keras.models.load_model(os.environ['MODEL_PATH_TF'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!saved_model_cli show \\\n",
    "  --dir $MODEL_PATH_TF \\\n",
    "  --tag_set serve  \\\n",
    "  --signature_def serving_default"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\n",
    "                           SIGNATURE_DEF_KEY [--inputs INPUTS]\n",
    "                           [--input_exprs INPUT_EXPRS]\n",
    "                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\n",
    "                           [--overwrite] [--tf_debug] [--worker WORKER]\n",
    "                           [--init_tpu]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = list(CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "builder = tfds.builder(\n",
    "    'test_dataset',\n",
    "    data_dir='101_ObjectCategories',\n",
    ")\n",
    "dataset = builder.as_dataset(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:34:56.401928Z",
     "start_time": "2020-04-27T05:34:56.395109Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import math\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:34:58.517995Z",
     "start_time": "2020-04-27T05:34:58.487943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['101_ObjectCategories/revolver/image_0077.jpg',\n",
       " '101_ObjectCategories/revolver/image_0053.jpg',\n",
       " '101_ObjectCategories/revolver/image_0030.jpg',\n",
       " '101_ObjectCategories/revolver/image_0027.jpg',\n",
       " '101_ObjectCategories/revolver/image_0070.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_paths = glob(\"101_ObjectCategories/*[!BACKGROUND_Google]/*.jpg\")\n",
    "print(len(raw_data_paths))\n",
    "raw_data_paths[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T16:09:25.017802Z",
     "start_time": "2020-04-24T16:09:18.697276Z"
    }
   },
   "source": [
    "raw_data_list = [get_proper_image_path(p) for p in raw_data_paths]\n",
    "for _, __ in enumerate(raw_data_list[:10]):\n",
    "    print(f'{_}\\t{__.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:35:02.026594Z",
     "start_time": "2020-04-27T05:35:02.021093Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_proper_image_path(img_path):\n",
    "    x = Image.open(img_path)\n",
    "    x = np.asarray(x)\n",
    "    return img_path if x.ndim > 2 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:35:08.982497Z",
     "start_time": "2020-04-27T05:35:02.861211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7077\n"
     ]
    }
   ],
   "source": [
    "data_paths = list(filter(None, (get_proper_image_path(p) for p in raw_data_paths)))\n",
    "print(len(data_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:35:08.991564Z",
     "start_time": "2020-04-27T05:35:08.989251Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image(img_path):\n",
    "    x = Image.open(img_path)\n",
    "    x = np.asarray(x)\n",
    "    # x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:25:19.745221Z",
     "start_time": "2020-04-24T19:25:19.739088Z"
    }
   },
   "source": [
    "def get_prep_image(img_path):\n",
    "    # x = Image.open(img_path)\n",
    "    x = tf.keras.preprocessing.image.load_img(\n",
    "        img_path,\n",
    "        grayscale=False,\n",
    "        color_mode='rgb',\n",
    "        target_size=(224, 224),\n",
    "        interpolation='nearest',\n",
    "    )\n",
    "    x = np.asarray(x)\n",
    "    x = preprocess_input(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:35:10.805762Z",
     "start_time": "2020-04-27T05:35:08.997997Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: unipy in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (0.1.27)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: oauth2client>=4.1.2 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (4.1.3)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.20.2 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.18.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.20.0)\n",
      "Requirement already satisfied, skipping upgrade: statsmodels>=0.8.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: pandasql>=0.7.3 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.7.3)\n",
      "Requirement already satisfied, skipping upgrade: seaborn>=0.8 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.10.1)\n",
      "Requirement already satisfied, skipping upgrade: PyDrive>=1.2.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: mglearn>=0.1.6 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib>=0.2.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.2 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image>=0.13.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.16.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: numpydoc>=0.7.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.9.2)\n",
      "Requirement already satisfied, skipping upgrade: paramiko>=2.1.2 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (2.7.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.4.3 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from unipy) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.6.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from oauth2client>=4.1.2->unipy) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from oauth2client>=4.1.2->unipy) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: httplib2>=0.9.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from oauth2client>=4.1.2->unipy) (0.17.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from pandas>=0.20.2->unipy) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from pandas>=0.20.2->unipy) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from statsmodels>=0.8.0->unipy) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: sqlalchemy in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from pandasql>=0.7.3->unipy) (1.3.16)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML>=3.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from PyDrive>=1.2.1->unipy) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-python-client>=1.2 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from PyDrive>=1.2.1->unipy) (1.8.2)\n",
      "Requirement already satisfied, skipping upgrade: cycler in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from mglearn>=0.1.6->unipy) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from mglearn>=0.1.6->unipy) (7.0.0)\n",
      "Requirement already satisfied, skipping upgrade: imageio in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from mglearn>=0.1.6->unipy) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-auth-oauthlib>=0.2.0->unipy) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-auth-oauthlib>=0.2.0->unipy) (1.14.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from matplotlib>=2.0.2->unipy) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from matplotlib>=2.0.2->unipy) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from scikit-image>=0.13.0->unipy) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from scikit-image>=0.13.0->unipy) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: sphinx>=1.6.5 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from numpydoc>=0.7.0->unipy) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.3 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from numpydoc>=0.7.0->unipy) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: pynacl>=1.0.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from paramiko>=2.1.2->unipy) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.5 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from paramiko>=2.1.2->unipy) (2.9.2)\n",
      "Requirement already satisfied, skipping upgrade: bcrypt>=3.1.3 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from paramiko>=2.1.2->unipy) (3.1.7)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.13.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-api-python-client>=1.2->PyDrive>=1.2.1->unipy) (1.17.0)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-api-python-client>=1.2->PyDrive>=1.2.1->unipy) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-api-python-client>=1.2->PyDrive>=1.2.1->unipy) (0.0.3)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.2.0->unipy) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.2.0->unipy) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-auth->google-auth-oauthlib>=0.2.0->unipy) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-auth->google-auth-oauthlib>=0.2.0->unipy) (46.1.3.post20200330)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.13.0->unipy) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-jsmath in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: alabaster<0.8,>=0.7 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (0.7.12)\n",
      "Requirement already satisfied, skipping upgrade: babel>=1.3 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: imagesize in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-htmlhelp in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-qthelp in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: Pygments>=2.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (20.3)\n",
      "Requirement already satisfied, skipping upgrade: docutils>=0.12 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (0.16)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-devhelp in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-applehelp in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: snowballstemmer>=1.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-serializinghtml in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from sphinx>=1.6.5->numpydoc>=0.7.0->unipy) (1.1.4)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from Jinja2>=2.3->numpydoc>=0.7.0->unipy) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.4.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from pynacl>=1.0.1->paramiko>=2.1.2->unipy) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client>=1.2->PyDrive>=1.2.1->unipy) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client>=1.2->PyDrive>=1.2.1->unipy) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.2.0->unipy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.2.0->unipy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.2.0->unipy) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.2.0->unipy) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko>=2.1.2->unipy) (2.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade unipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:35:13.198126Z",
     "start_time": "2020-04-27T05:35:12.784957Z"
    }
   },
   "outputs": [],
   "source": [
    "from unipy.utils.generator import ReusableGenerator, re_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:38:44.336897Z",
     "start_time": "2020-04-27T05:38:44.330394Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prep_image(img_path, target_size=None):\n",
    "    x = tf.keras.preprocessing.image.load_img(\n",
    "        img_path,\n",
    "        grayscale=False,\n",
    "        color_mode='rgb',  # Image\n",
    "        target_size=target_size,\n",
    "        interpolation='nearest',\n",
    "    )\n",
    "    x = np.asarray(x)\n",
    "    x = preprocess_input(x)  # mode: One of \"caffe\", \"tf\", \"torch\"\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x\n",
    "\n",
    "# mode: One of \"caffe\", \"tf\" or \"torch\".\n",
    "#     - caffe: will convert the images from RGB to BGR,\n",
    "#         then will zero-center each color channel with\n",
    "#         respect to the ImageNet dataset,\n",
    "#         without scaling.\n",
    "#     - tf: will scale pixels between -1 and 1,\n",
    "#         sample-wise.\n",
    "#     - torch: will scale pixels between 0 and 1 and then\n",
    "#         will normalize each channel with respect to the\n",
    "#         ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:38:44.781330Z",
     "start_time": "2020-04-27T05:38:44.771930Z"
    }
   },
   "outputs": [],
   "source": [
    "data_array_gen = (get_image(f) for f in data_paths)\n",
    "data_prep_gen = (get_prep_image(f) for f in data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:44:52.121706Z",
     "start_time": "2020-04-27T05:38:45.479571Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7077/7077 [==============================] - 367s 52ms/step\n",
      "366.63552295800764\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "import time\n",
    "\n",
    "\n",
    "t = time.perf_counter()\n",
    "\n",
    "pred = tf_model.predict(\n",
    "    data_prep_gen,\n",
    "    steps=len(data_paths),\n",
    "    workers=1,\n",
    "    max_queue_size=128,  # Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. \n",
    "    use_multiprocessing=False,  # Used for generator or keras.utils.Sequence input only.\n",
    "    verbose=1,\n",
    ")\n",
    "print(time.perf_counter() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS\n",
    "bdf1a647146f        admiring_wu         579.78%             28.77GiB / 62.85GiB   45.77%              2.2GB / 717MB       840MB / 2.26GB      227\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:44:56.346516Z",
     "start_time": "2020-04-27T05:44:55.382886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1000,)\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 0s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('n02437616', 'llama', 0.15925159),\n",
       "  ('n02417914', 'ibex', 0.10049338),\n",
       "  ('n02391049', 'zebra', 0.07378857),\n",
       "  ('n02423022', 'gazelle', 0.041579306),\n",
       "  ('n02125311', 'cougar', 0.02804535)],\n",
       " [('n02389026', 'sorrel', 0.17463423),\n",
       "  ('n02391049', 'zebra', 0.06998125),\n",
       "  ('n02437312', 'Arabian_camel', 0.056545377),\n",
       "  ('n02417914', 'ibex', 0.051300034),\n",
       "  ('n02422106', 'hartebeest', 0.03356029)],\n",
       " [('n02391049', 'zebra', 0.63725334),\n",
       "  ('n02389026', 'sorrel', 0.15998408),\n",
       "  ('n02423022', 'gazelle', 0.0069316197),\n",
       "  ('n03967562', 'plow', 0.0067086597),\n",
       "  ('n03538406', 'horse_cart', 0.004334446)]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(pred))\n",
    "print(pred[0].shape)\n",
    "\n",
    "pred_decoded_tf = decode_predictions(pred)\n",
    "pred_decoded_tf[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN `onnx_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:46:06.027193Z",
     "start_time": "2020-04-27T05:46:06.023756Z"
    }
   },
   "outputs": [],
   "source": [
    "import onnx.onnx_cpp2py_export.optimizer as C\n",
    "\n",
    "os.environ['ONNX_MODEL_PATH'] = ONNX_MODEL_PATH = os.path.join(\n",
    "    MODEL_PATH_TF,\n",
    "    'onnx_model',\n",
    "    'from_frozen_with_keras2onnx.onnx',\n",
    ")\n",
    "\n",
    "# onnx_model = onnx.load(ONNX_MODEL_PATH)\n",
    "# onnx_model_str = onnx_model.SerializeToString()\n",
    "# optimized_model_str = C.optimize(onnx_model_str, passes=None)\n",
    "# onnx_model_optimized = onnx.load_from_string(optimized_model_str)\n",
    "# onnx_model_optimized = onnx.optimizer.optimize(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:46:06.120750Z",
     "start_time": "2020-04-27T05:46:06.028319Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_array_gen = (get_image(f) for f in data_paths)\n",
    "data_prep_gen = ReusableGenerator(get_prep_image(f) for f in data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:46:06.206863Z",
     "start_time": "2020-04-27T05:46:06.127285Z"
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as rt\n",
    "import onnx.onnx_cpp2py_export.optimizer as C\n",
    "\n",
    "\n",
    "class ONNXInference(object):\n",
    "    def __init__(self, model_path, optimize=False):\n",
    "        self.model = onnx.load(model_path)\n",
    "        if optimize:\n",
    "            onnx_model_str = self.model.SerializeToString()\n",
    "            optimized_model_str = C.optimize(onnx_model_str, passes=None)\n",
    "            self.model = onnx.load_from_string(optimized_model_str)\n",
    "\n",
    "        self._prepare_runtime(model_path)\n",
    "    \n",
    "    def _prepare_runtime(self, model_path):\n",
    "        self.sess = rt.InferenceSession(os.path.join(model_path))\n",
    "        self.onnx_inputs = [i.name for i in self.sess.get_inputs()]\n",
    "        self.onnx_outputs = [o.name for o in self.sess.get_outputs()]\n",
    "        \n",
    "        print(f'inputs : {self.onnx_inputs}')\n",
    "        print(f'outputs: {self.onnx_outputs}')\n",
    "        #self.onnx_model = onnx.load(model_path)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if len(x) == len(self.onnx_inputs):\n",
    "            input_dict = {i: x_i for i, x_i in zip(self.onnx_inputs, x)}\n",
    "            return self.sess.run(self.onnx_outputs, input_dict)\n",
    "        else:\n",
    "            raise Exception(f\"The given input number '{len(x)}' and onnx model input number should be the same.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:46:06.690609Z",
     "start_time": "2020-04-27T05:46:06.212750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs : ['input_8']\n",
      "outputs: ['probs']\n"
     ]
    }
   ],
   "source": [
    "onnx_infe_model = ONNXInference(ONNX_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Error: `INVALID_ARGUMENT: Invalid rank for input`: expand a rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T06:01:31.100651Z",
     "start_time": "2020-04-25T06:01:31.062260Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid rank for input: input_11 Got: 3 Expected: 4 Please fix either the inputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-496-55e97e795691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_prep_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prep_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0monnx_infe_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_prep_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-496-55e97e795691>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_prep_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prep_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0monnx_infe_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_prep_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-494-8a5b0484dd1b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The given input number '{len(x)}' and onnx model input number should be the same.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid rank for input: input_11 Got: 3 Expected: 4 Please fix either the inputs or the model."
     ]
    }
   ],
   "source": [
    "data_prep_gen = ReusableGenerator(get_prep_image(f) for f in data_paths)\n",
    "\n",
    "pred = [onnx_infe_model.predict(img) for img in data_prep_gen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Error</b> <br>\n",
    "    \n",
    "```sh\n",
    "inputs : ['input_11']\n",
    "outputs: ['probs']\n",
    "(1, 224, 224, 3)\n",
    "---------------------------------------------------------------------------\n",
    "InvalidArgument                           Traceback (most recent call last)\n",
    "<ipython-input-496-55e97e795691> in <module>\n",
    "      1 data_prep_gen = ((get_prep_image(f) for f in data_paths))\n",
    "----> 2 pred = [onnx_infe_model.predict(img) for img in data_prep_gen]\n",
    "\n",
    "<ipython-input-496-55e97e795691> in <listcomp>(.0)\n",
    "      1 data_prep_gen = ((get_prep_image(f) for f in data_paths))\n",
    "----> 2 pred = [onnx_infe_model.predict(img) for img in data_prep_gen]\n",
    "\n",
    "<ipython-input-494-8a5b0484dd1b> in predict(self, x)\n",
    "     26         if len(x) == len(self.onnx_inputs):\n",
    "     27             input_dict = {i: x_i for i, x_i in zip(self.onnx_inputs, x)}\n",
    "---> 28             return self.sess.run(self.onnx_outputs, input_dict)\n",
    "     29         else:\n",
    "     30             raise Exception(f\"The given input number '{len(x)}' and onnx model input number should be the same.\")\n",
    "\n",
    "/opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages/onnxruntime/capi/session.py in run(self, output_names, input_feed, run_options)\n",
    "    140             output_names = [output.name for output in self._outputs_meta]\n",
    "    141         try:\n",
    "--> 142             return self._sess.run(output_names, input_feed, run_options)\n",
    "    143         except C.EPFail as err:\n",
    "    144             if self._enable_fallback:\n",
    "\n",
    "InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid rank for input: input_11 Got: 3 Expected: 4 Please fix either the inputs or the model.\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    ": ONNX loaded model requires an expanded axis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Error: `INVALID_ARGUMENT: Got invalid dimensions for Input`: ONNX need fixed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T06:04:24.060918Z",
     "start_time": "2020-04-25T06:04:24.023969Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input_11 for the following indices\n index: 1 Got: 197 Expected: 224\n index: 2 Got: 300 Expected: 224\n Please fix either the inputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-499-92ec9554f4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_prep_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prep_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0monnx_infe_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_prep_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-499-92ec9554f4cf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_prep_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prep_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0monnx_infe_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_prep_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-494-8a5b0484dd1b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The given input number '{len(x)}' and onnx model input number should be the same.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input_11 for the following indices\n index: 1 Got: 197 Expected: 224\n index: 2 Got: 300 Expected: 224\n Please fix either the inputs or the model."
     ]
    }
   ],
   "source": [
    "data_prep_gen = ReusableGenerator(np.expand_dims(get_prep_image(f), axis=0) for f in data_paths)\n",
    "\n",
    "pred = [onnx_infe_model.predict(img) for img in data_prep_gen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Error</b> <br>\n",
    "    \n",
    "```sh\n",
    "inputs : ['input_11']\n",
    "outputs: ['probs']\n",
    "(1, 1, 197, 300, 3)\n",
    "---------------------------------------------------------------------------\n",
    "InvalidArgument                           Traceback (most recent call last)\n",
    "<ipython-input-499-92ec9554f4cf> in <module>\n",
    "      1 data_prep_gen = (np.expand_dims(get_prep_image(f), axis=0) for f in data_paths)\n",
    "      2 \n",
    "----> 3 pred = [onnx_infe_model.predict(img) for img in data_prep_gen]\n",
    "\n",
    "<ipython-input-499-92ec9554f4cf> in <listcomp>(.0)\n",
    "      1 data_prep_gen = (np.expand_dims(get_prep_image(f), axis=0) for f in data_paths)\n",
    "      2 \n",
    "----> 3 pred = [onnx_infe_model.predict(img) for img in data_prep_gen]\n",
    "\n",
    "<ipython-input-494-8a5b0484dd1b> in predict(self, x)\n",
    "     26         if len(x) == len(self.onnx_inputs):\n",
    "     27             input_dict = {i: x_i for i, x_i in zip(self.onnx_inputs, x)}\n",
    "---> 28             return self.sess.run(self.onnx_outputs, input_dict)\n",
    "     29         else:\n",
    "     30             raise Exception(f\"The given input number '{len(x)}' and onnx model input number should be the same.\")\n",
    "\n",
    "/opt/conda/envs/onnx-tf1-15/lib/python3.7/site-packages/onnxruntime/capi/session.py in run(self, output_names, input_feed, run_options)\n",
    "    140             output_names = [output.name for output in self._outputs_meta]\n",
    "    141         try:\n",
    "--> 142             return self._sess.run(output_names, input_feed, run_options)\n",
    "    143         except C.EPFail as err:\n",
    "    144             if self._enable_fallback:\n",
    "\n",
    "InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input_11 for the following indices\n",
    " index: 1 Got: 197 Expected: 224\n",
    " index: 2 Got: 300 Expected: 224\n",
    " Please fix either the inputs or the model.\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    ": ONNX loaded model requires a fixed size input.  \n",
    "\n",
    "[ref1: Common errors with `onnxruntime`](http://www.xavierdupre.fr/app/onnxruntime/helpsphinx/auto_examples/plot_common_errors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:46:40.835077Z",
     "start_time": "2020-04-27T05:46:40.830461Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prep_image(img_path, target_size=None):\n",
    "    x = tf.keras.preprocessing.image.load_img(\n",
    "        img_path,\n",
    "        grayscale=False,\n",
    "        color_mode='rgb',\n",
    "        target_size=target_size,\n",
    "        interpolation='nearest',\n",
    "    )\n",
    "    x = np.asarray(x)\n",
    "    x = preprocess_input(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:46:41.063586Z",
     "start_time": "2020-04-27T05:46:41.052095Z"
    }
   },
   "outputs": [],
   "source": [
    "data_prep_fixed_size_gen = ReusableGenerator(get_prep_image(f, target_size=(224, 224)) for f in data_paths)\n",
    "data_prep_for_onnx_gen = ReusableGenerator(np.expand_dims(l, axis=0) for l in data_prep_fixed_size_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:51:17.800791Z",
     "start_time": "2020-04-27T05:46:41.555468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276.23671409802046\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "t = time.perf_counter()\n",
    "\n",
    "pred = [onnx_infe_model.predict(img)[0] for img in data_prep_for_onnx_gen]\n",
    "print(time.perf_counter() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS\n",
    "bdf1a647146f        admiring_wu         312.80%             28.86GiB / 62.85GiB   45.92%              2.22GB / 726MB      841MB / 2.29GB      232\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:52:15.019967Z",
     "start_time": "2020-04-27T05:52:14.651252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('n02437616', 'llama', 0.43486962),\n",
       "  ('n01873310', 'platypus', 0.19912402),\n",
       "  ('n02417914', 'ibex', 0.18232316),\n",
       "  ('n02326432', 'hare', 0.027106483),\n",
       "  ('n01877812', 'wallaby', 0.018452054)],\n",
       " [('n02389026', 'sorrel', 0.39518663),\n",
       "  ('n02417914', 'ibex', 0.24218312),\n",
       "  ('n02422106', 'hartebeest', 0.20695865),\n",
       "  ('n02437312', 'Arabian_camel', 0.035300635),\n",
       "  ('n02423022', 'gazelle', 0.027825477)],\n",
       " [('n02391049', 'zebra', 0.8434858),\n",
       "  ('n02389026', 'sorrel', 0.089342676),\n",
       "  ('n02116738', 'African_hunting_dog', 0.0052763782),\n",
       "  ('n02091244', 'Ibizan_hound', 0.0048087235),\n",
       "  ('n02509815', 'lesser_panda', 0.002450595)]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_array = np.concatenate(pred)\n",
    "\n",
    "print(type(pred_array))\n",
    "print(pred_array[0].shape)\n",
    "\n",
    "pred_decoded_onnx = decode_predictions(pred_array)\n",
    "pred_decoded_onnx[-3:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[('n02437616', 'llama', 0.15925159),\n",
    "  ('n02417914', 'ibex', 0.10049338),\n",
    "  ('n02391049', 'zebra', 0.07378857),\n",
    "  ('n02423022', 'gazelle', 0.041579306),\n",
    "  ('n02125311', 'cougar', 0.02804535)],\n",
    " [('n02389026', 'sorrel', 0.17463423),\n",
    "  ('n02391049', 'zebra', 0.06998125),\n",
    "  ('n02437312', 'Arabian_camel', 0.056545377),\n",
    "  ('n02417914', 'ibex', 0.051300034),\n",
    "  ('n02422106', 'hartebeest', 0.03356029)],\n",
    " [('n02391049', 'zebra', 0.63725334),\n",
    "  ('n02389026', 'sorrel', 0.15998408),\n",
    "  ('n02423022', 'gazelle', 0.0069316197),\n",
    "  ('n03967562', 'plow', 0.0067086597),\n",
    "  ('n03538406', 'horse_cart', 0.004334446)]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[('n02437616', 'llama', 0.43486962),\n",
    "  ('n01873310', 'platypus', 0.19912402),\n",
    "  ('n02417914', 'ibex', 0.18232316),\n",
    "  ('n02326432', 'hare', 0.027106483),\n",
    "  ('n01877812', 'wallaby', 0.018452054)],\n",
    " [('n02389026', 'sorrel', 0.39518663),\n",
    "  ('n02417914', 'ibex', 0.24218312),\n",
    "  ('n02422106', 'hartebeest', 0.20695865),\n",
    "  ('n02437312', 'Arabian_camel', 0.035300635),\n",
    "  ('n02423022', 'gazelle', 0.027825477)],\n",
    " [('n02391049', 'zebra', 0.8434858),\n",
    "  ('n02389026', 'sorrel', 0.089342676),\n",
    "  ('n02116738', 'African_hunting_dog', 0.0052763782),\n",
    "  ('n02091244', 'Ibizan_hound', 0.0048087235),\n",
    "  ('n02509815', 'lesser_panda', 0.002450595)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T19:44:39.744111Z",
     "start_time": "2020-04-25T19:44:39.737526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.1'"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_infe_model.model.producer_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T19:45:09.161950Z",
     "start_time": "2020-04-25T19:45:09.156246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.protobuf.pyext._message.MessageDescriptor at 0x7f3bf8860c50>"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_infe_model.model.DESCRIPTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T16:52:52.788062Z",
     "start_time": "2020-04-24T16:52:52.548620Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shape inference, the shape info of Y is:\n",
      "[name: \"input_11:01_permuted\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"N\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 3\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 224\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 224\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"input_11:01_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"N\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 3\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 230\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 230\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output50\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv1_conv_10/BiasAdd:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"pool1_pad_10/Pad:0_pooling0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer42\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block1_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output52\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer46\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block1_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block1_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output48\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer43\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block1_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output44\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output43\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block1_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer48\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block2_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output51\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer45\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block2_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block2_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output47\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer40\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block2_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output41\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block2_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer47\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block3_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output49\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer44\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block3_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block3_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output45\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer37\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block3_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output39\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block2_out_10/add:0_pooling0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv2_block3_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer31\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block1_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output46\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer38\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block1_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block1_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output37\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer32\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block1_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output34\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output33\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block1_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer41\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block2_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output42\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer35\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block2_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block2_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output36\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer30\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block2_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output30\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block2_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer39\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block3_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output40\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer34\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block3_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block3_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output35\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer28\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block3_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output28\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block3_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer36\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block4_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output38\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer33\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block4_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block4_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output31\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer24\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block4_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output25\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block3_out_10/add:0_pooling0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv3_block4_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer16\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block1_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output32\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer25\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block1_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block1_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output23\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer17\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block1_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output18\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output17\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block1_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer29\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block2_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output29\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer22\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block2_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block2_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output22\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer15\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block2_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output15\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block2_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer27\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block3_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output27\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer21\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block3_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block3_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output20\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer13\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block3_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output14\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block3_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer26\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block4_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output26\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer19\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block4_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block4_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output19\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer12\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block4_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output11\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block4_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer23\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block5_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output24\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer18\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block5_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block5_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output16\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer10\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block5_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output9\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block5_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer20\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block6_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output21\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer14\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block6_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block6_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output12\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer7\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block6_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output7\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block5_out_10/add:0_pooling0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv4_block6_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer3\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block1_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output13\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer8\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block1_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block1_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output6\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer4\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block1_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output3\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output2\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block1_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer11\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block2_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output10\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer6\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block2_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block2_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output5\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer2\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block2_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output1\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block2_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer9\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block3_preact_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output8\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer5\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block3_1_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block3_1_relu_10/Relu:0_permuted_padded\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output4\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer1\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block3_2_relu_10/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"convolution_output\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"conv5_block3_out_10/add:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"batch_norm_output_buffer\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"post_relu_8/Relu:0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"post_relu_8/Relu:0_pooling0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"post_relu_8/Relu:0_transpose0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"post_relu_8/Relu:0_reshape0\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"transformed_tensor\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"biased_tensor_name\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      ", name: \"probs_10/Softmax:01\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from onnx import helper, shape_inference\n",
    "\n",
    "\n",
    "# Apply shape inference on the model\n",
    "inferred_model = shape_inference.infer_shapes(onnx_model)\n",
    "\n",
    "# Check the model and print Y's shape information\n",
    "onnx.checker.check_model(inferred_model)\n",
    "print('After shape inference, the shape info of Y is:\\n{}'.format(inferred_model.graph.value_info))\n",
    "\n",
    "# Function polish_model runs model checker, optimizer, shape inference engine on the model,\n",
    "# and also strips the doc_string for you.\n",
    "polished_model = onnx.utils.polish_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Runtime Server\n",
    "*Public Preview*\n",
    "\n",
    "**Ubuntu 16.04**\n",
    "\n",
    "1. Build the docker image from the Dockerfile in this repository\n",
    "  ```bash\n",
    "  docker build -t {docker_image_name} -f Dockerfile.server .\n",
    "  ```\n",
    "\n",
    "2. Run the ONNXRuntime server with the image created in step 1\n",
    "\n",
    "  ```bash\n",
    "  docker run -v {localModelAbsoluteFolder}:{dockerModelAbsoluteFolder} -p {your_local_port}:8001 {imageName} --model_path {dockerModelAbsolutePath}\n",
    "  ```\n",
    "3. Send HTTP requests to the container running ONNX Runtime Server\n",
    "\n",
    "  Send HTTP requests to the docker container through the binding local port. Here is the full [usage document](https://github.com/Microsoft/onnxruntime/blob/master/docs/ONNX_Runtime_Server_Usage.md).\n",
    "  ```bash\n",
    "  curl  -X POST -d \"@request.json\" -H \"Content-Type: application/json\" http://0.0.0.0:{your_local_port}/v1/models/mymodel/versions/3:predict  \n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T18:06:04.061758Z",
     "start_time": "2020-04-25T18:06:04.056519Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['ONNX_MODEL_DIR'] = ONNX_MODEL_DIR = os.path.dirname(os.environ['ONNX_MODEL_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T18:04:12.217011Z",
     "start_time": "2020-04-25T18:04:12.211650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/trained_models/resnet50/onnx_model/'"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['ONNX_MODEL_PATH'] = f'{MODEL_PATH}/onnx_model/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T18:17:26.174278Z",
     "start_time": "2020-04-25T18:17:06.320884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///workspace/trained_models/resnet50/onnx_model/from_frozen_with_keras2onnx.onnx [Content-Type=application/octet-stream]...\n",
      "| [1/1 files][ 97.8 MiB/ 97.8 MiB] 100% Done   7.1 MiB/s ETA 00:00:00           \n",
      "Operation completed over 1 objects/97.8 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r $ONNX_MODEL_DIR gs://yjkim-outputs/onnx/converted/tfkeras/resnet50/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run \\\n",
    "    -v \"{localModelAbsoluteFolder}:{dockerModelAbsoluteFolder}\" \\\n",
    "    -p \"{your_local_port}:8001\" \\\n",
    "    \"{imageName}\" \\\n",
    "        --model_path \"{dockerModelAbsolutePath}\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "docker run \\\n",
    "    -v \"/mnt/hdc1/data/git/ai-ml-ops/docker/onnx-containers/onnx-tensorflow/onnxruntime_server:/onnxruntime/model\" \\\n",
    "    -p 8001:8001 \\\n",
    "    \"mcr.microsoft.com/onnxruntime/server\" \\\n",
    "        --model_path \"/onnxruntime/model/from_frozen_with_keras2onnx.onnx\"\n",
    "```\n",
    "or\n",
    "\n",
    "```bash\n",
    "docker run \\\n",
    "    -it \\\n",
    "    -v \"/mnt/hdc1/data/git/ai-ml-ops/docker/onnx-containers/onnx-tensorflow/onnxruntime_server:/onnxruntime/model\" \\\n",
    "    -p 9001:8001 \\\n",
    "    -p 50051:50051 \\\n",
    "    --name \"ort\" \\\n",
    "    \"mcr.microsoft.com/onnxruntime/server\" \\\n",
    "        --model_path=\"/onnxruntime/model/from_frozen_with_keras2onnx.onnx\"\n",
    "```\n",
    "\n",
    "* `8001: HTTP`\n",
    "* `50051: gRPC`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP Endpoint\n",
    "\n",
    "The prediction URL for HTTP endpoint is in this format:\n",
    "\n",
    "```url\n",
    "http://<your_ip_address>:<port>/v1/models/<your-model-name>/versions/<your-version>:predict\n",
    "```\n",
    "\n",
    "**Note**: Since we currently only support one model, the model name and version can be any string length > 0. In the future, model_names and versions will be verified.\n",
    "\n",
    "### Request and Response Payload\n",
    "\n",
    "The request and response need to be a protobuf message. The Protobuf definition can be found [here](../onnxruntime/server/protobuf/predict.proto).\n",
    "\n",
    "A protobuf message could have two formats: binary and JSON. Usually the binary payload has better latency, in the meanwhile the JSON format is easy for human readability. \n",
    "\n",
    "The HTTP request header field `Content-Type` tells the server how to handle the request and thus it is mandatory for all requests. Requests missing `Content-Type` will be rejected as `400 Bad Request`.\n",
    "\n",
    "* For `\"Content-Type: application/json\"`, the payload will be deserialized as JSON string in UTF-8 format\n",
    "* For `\"Content-Type: application/vnd.google.protobuf\"`, `\"Content-Type: application/x-protobuf\"` or `\"Content-Type: application/octet-stream\"`, the payload will be consumed as protobuf message directly.\n",
    "\n",
    "Clients can control the response type by setting the request with an `Accept` header field and the server will serialize in your desired format. The choices currently available are the same as the `Content-Type` header field. If this field is not set in the request, the server will use the same type as your request.\n",
    "\n",
    "### Inferencing\n",
    "\n",
    "To send a request to the server, you can use any tool which supports making HTTP requests. Here is an example using `curl`:\n",
    "\n",
    "```bash\n",
    "curl -X POST -d \"@predict_request_0.json\" -H \"Content-Type: application/json\" http://127.0.0.1:8001/v1/models/mymodel/versions/3:predict\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "curl -X POST --data-binary \"@predict_request_0.pb\" -H \"Content-Type: application/octet-stream\" -H \"Foo: 1234\"  http://127.0.0.1:8001/v1/models/mymodel/versions/3:predict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HTTP Endpoint\n",
    "\n",
    "```url\n",
    "http://<your_ip_address>:<port>/v1/models/<your-model-name>/versions/<your-version>:predict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:53:11.034115Z",
     "start_time": "2020-04-27T05:53:11.029363Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from assets import onnx_ml_pb2\n",
    "from assets import predict_pb2\n",
    "\n",
    "import google.protobuf.json_format as json_format\n",
    "from google.protobuf.json_format import MessageToJson"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "echo \"model name: $MODEL_NAME\"\n",
    "echo \"service url: $SERVICE_HOSTNAME\"\n",
    "echo \"cluster ip: $CLUSTER_IP\"\n",
    "\n",
    "# model name: style-sample\n",
    "# service url: style-sample.default.example.com\n",
    "# cluster ip: 52.247.193.219"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HTTP Endpoint\n",
    "\n",
    "```url\n",
    "http://<your_ip_address>:<port>/v1/models/<your-model-name>/versions/<your-version>:predict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:53:11.121955Z",
     "start_time": "2020-04-27T05:53:11.035179Z"
    }
   },
   "outputs": [],
   "source": [
    "data_prep_fixed_size_gen = ReusableGenerator(get_prep_image(f, target_size=(224, 224)) for f in data_paths)\n",
    "data_prep_for_onnx_gen = ReusableGenerator(np.expand_dims(l, axis=0) for l in data_prep_fixed_size_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:53:11.197923Z",
     "start_time": "2020-04-27T05:53:11.126081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_8']\n",
      "['probs']\n"
     ]
    }
   ],
   "source": [
    "print(onnx_infe_model.onnx_inputs)\n",
    "print(onnx_infe_model.onnx_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:55:32.324694Z",
     "start_time": "2020-04-27T05:55:32.317173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create request message to be sent to the predictor\n",
    "def request_prediction(img):\n",
    "    # img = np.transpose(img, [2, 0, 1])\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    input_tensor = onnx_ml_pb2.TensorProto()\n",
    "    input_tensor.dims.extend(img.shape)\n",
    "    input_tensor.data_type = 1\n",
    "    input_tensor.raw_data = img.tobytes()\n",
    "    \n",
    "    request_message = predict_pb2.PredictRequest()\n",
    "    request_message.inputs[\"input_11\"].data_type = input_tensor.data_type\n",
    "    request_message.inputs[\"input_11\"].dims.extend(input_tensor.dims)\n",
    "    request_message.inputs[\"input_11\"].raw_data = input_tensor.raw_data\n",
    "    \n",
    "    # write message data to JSON\n",
    "    return json_format.MessageToJson(request_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:55:54.177591Z",
     "start_time": "2020-04-27T05:55:53.847661Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdbf208bcd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "aa = next(data_prep_fixed_size_gen)\n",
    "#request_msg = request_prediction(aa)\n",
    "\n",
    "bb = next(data_prep_for_onnx_gen)\n",
    "#request_msg = request_prediction(bb)\n",
    "\n",
    "cc = aa[0]\n",
    "print(cc.shape)\n",
    "plt.imshow(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:02:21.144841Z",
     "start_time": "2020-04-27T05:56:02.274248Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[('n02437616', 'llama', 0.43487042),\n",
       "   ('n01873310', 'platypus', 0.19912325),\n",
       "   ('n02417914', 'ibex', 0.18232298),\n",
       "   ('n02326432', 'hare', 0.027106429),\n",
       "   ('n01877812', 'wallaby', 0.018452052)]],\n",
       " [[('n02389026', 'sorrel', 0.3951849),\n",
       "   ('n02417914', 'ibex', 0.24218436),\n",
       "   ('n02422106', 'hartebeest', 0.20695913),\n",
       "   ('n02437312', 'Arabian_camel', 0.035300612),\n",
       "   ('n02423022', 'gazelle', 0.02782558)]],\n",
       " [[('n02391049', 'zebra', 0.84348476),\n",
       "   ('n02389026', 'sorrel', 0.089343),\n",
       "   ('n02116738', 'African_hunting_dog', 0.005276417),\n",
       "   ('n02091244', 'Ibizan_hound', 0.0048087407),\n",
       "   ('n02509815', 'lesser_panda', 0.0024506175)]]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_url = 'http://172.17.0.3:8001/v1/models/default/versions/1:predict'\n",
    "\n",
    "result = []\n",
    "for _ in data_prep_fixed_size_gen:\n",
    "    \n",
    "    img = _[0]\n",
    "    request_msg = request_prediction(img)\n",
    "    \n",
    "\n",
    "    # Call predictor\n",
    "    request_headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json',\n",
    "        'Host': '7d5af6497531',\n",
    "    }\n",
    "    response = requests.post(\n",
    "        predictor_url,\n",
    "        headers=request_headers,\n",
    "        data=request_msg,\n",
    "    )\n",
    "    response_parsed = json_format.Parse(response.text, predict_pb2.PredictResponse())\n",
    "    response_pred = np.frombuffer(response_parsed.outputs['probs'].raw_data, dtype=np.float32)\n",
    "    response_data = decode_predictions(np.expand_dims(response_pred, axis=0))\n",
    "    result += [response_data]\n",
    "\n",
    "result[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS\n",
    "bdf1a647146f        admiring_wu         13.73%              28.91GiB / 62.85GiB   46.00%              6.95GB / 6.25GB     1.44GB / 16.5GB     231\n",
    "b0b1b76efd26        suspicious_shtern   259.17%             210.5MiB / 62.85GiB   0.33%               5.34GB / 62.1MB     4.1kB / 0B          19\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build ONNXRuntime Server (`onnxruntime_server`)\n",
    "\n",
    "```bash\n",
    "git clone \\\n",
    "    -b rel-1.1.1 \\\n",
    "    --single-branch \\\n",
    "    https://github.com/microsoft/onnxruntime $WORKDIR/onnxruntime-git && \\\n",
    "cd $WORKDIR/onnxruntime-git && \\\n",
    "python ./tools/ci_build/build.py \\\n",
    "    --build_dir ./build \\\n",
    "    --config Release \\\n",
    "    --parallel \\\n",
    "    --cmake_extra_defines ONNXRUNTIME_VERSION=$(cat ./VERSION_NUMBER) && \\\n",
    "cd /\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Further Readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## How `tf2onnx` works\n",
    "\n",
    "The converter needs to take care of a few things:\n",
    "\n",
    "1. Convert the protobuf format. Since the format is similar this step is straight forward.\n",
    "2. **TensorFlow types need to be mapped to their ONNX equivalent.**\n",
    "3. For many ops TensorFlow passes **parameters like shapes as inputs** where ONNX wants to **_see them as attributes_**. Since we use a frozen graph, the converter will fetch the input as constant, converts it to an attribute and remove the original input.\n",
    "4. TensorFlow in many cases composes ops out of multiple simpler ops. The converter will need to identify the subgraph for such ops, slice the subgraph out and replace it with the ONNX equivalent. This can become fairly complex so we use a graph matching library for it. A good example of this is the tensorflow transpose op.\n",
    "5. TensorFlow's default data format is `NHWC` where ONNX requires `NCHW`. The converter will insert transpose ops to deal with this.\n",
    "6. There are **some ops like `relu6`** that are not supported in ONNX but the converter can be composed out of other ONNX ops.\n",
    "7. ONNX backends are new and their implementations are not complete yet. For some ops the converter generate ops with deal with issues in existing backends.\n",
    "\n",
    "---\n",
    "### Step 1 - start with a frozen graph\n",
    "\n",
    "tf2onnx starts with a frozen graph. This is because of item 3 above.\n",
    "\n",
    "### Step 2 - 1:1 convertion of the protobuf from tensorflow to onnx\n",
    "\n",
    "tf2onnx first does a simple conversion from the TensorFlow protobuf format to the ONNX protobuf format without looking at individual ops.\n",
    "We do this so we can use the ONNX graph as internal representation and write helper functions around it.\n",
    "The code that does the conversion is in tensorflow_to_onnx(). tensorflow_to_onnx() will return the ONNX graph and a dictionary with shape information from TensorFlow. The shape information is helpful in some cases when processing individual ops.\n",
    "The ONNX graph is wrapped in a Graph object and nodes in the graph are wrapped in a Node object to allow easier graph manipulations on the graph. All code that deals with nodes and graphs is in graph.py.\n",
    "\n",
    "### Step 3 - rewrite subgraphs\n",
    "\n",
    "In the next step we apply graph matching code on the graph to re-write subgraphs for ops like transpose and lstm. For an example looks at rewrite_transpose().\n",
    "\n",
    "### Step 4 - process individual ops\n",
    "\n",
    "In the fourth step we look at individual ops that need attention. The dictionary _OPS_MAPPING will map tensorflow op types to a method that is used to process the op. The simplest case is direct_op() where the op can be taken as is. Whenever possible we try to group ops into common processing, for example all ops that require dealing with broadcasting are mapped to broadcast_op(). For an op that composes the tensorflow op from multiple onnx ops, see relu6_op().\n",
    "\n",
    "### Step 5 - final processing\n",
    "\n",
    "Once all ops are converted, we need to do a topological sort since ONNX requires it. process_tf_graph() is the method that takes care of all above steps.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "From: [ONNX_Runtime_Server_Usage](https://raw.githubusercontent.com/microsoft/onnxruntime/master/docs/ONNX_Runtime_Server_Usage.md)\n",
    "\n",
    "---\n",
    "## How to Use ONNX Runtime Server for Prediction\n",
    "ONNX Runtime Server provides an easy way to start an inferencing server for prediction with both HTTP and GRPC endpoints.\n",
    "\n",
    "### Build the Server\n",
    "\n",
    "The CLI command to build the server is\n",
    "\n",
    "Default CPU:\n",
    "\n",
    "```bash\n",
    "python3 /onnxruntime/tools/ci_build/build.py --build_dir /onnxruntime/build --config Release --build_server -parallel --cmake_extra_defines ONNXRUNTIME_VERSION=$(cat ./VERSION_NUMBER\n",
    "```\n",
    "\n",
    "### Start the Server\n",
    "\n",
    "The CLI command to start the server is shown below:\n",
    "\n",
    "```bash\n",
    "$ ./onnxruntime_server\n",
    "Version: <Build number>\n",
    "Commit ID: <The latest commit ID>\n",
    "\n",
    "the option '--model_path' is required but missing\n",
    "Allowed options:\n",
    "  -h [ --help ]                Shows a help message and exits\n",
    "  --log_level arg (=info)      Logging level. Allowed options (case sensitive):\n",
    "                               verbose, info, warning, error, fatal\n",
    "  --model_path arg             Path to ONNX model\n",
    "  --address arg (=0.0.0.0)     The base HTTP address\n",
    "  --http_port arg (=8001)      HTTP port to listen to requests\n",
    "  --num_http_threads arg (=<# of your cpu cores>) Number of http threads\n",
    "  --grpc_port arg (=50051)     GRPC port to listen to requests\n",
    "```\n",
    "\n",
    "**Note**: The only mandatory argument for the program here is `model_path`\n",
    "\n",
    "\n",
    "* To host an ONNX model as an inferencing server, simply run:\n",
    "\n",
    "```bash\n",
    "./onnxruntime_server --model_path /<your>/<model>/<path>\n",
    "```\n",
    "\n",
    "### Endpoint\n",
    "\n",
    "#### HTTP Endpoint\n",
    "\n",
    "The prediction URL for HTTP endpoint is in this format:\n",
    "\n",
    "```url\n",
    "http://<your_ip_address>:<port>/v1/models/<your-model-name>/versions/<your-version>:predict\n",
    "```\n",
    "\n",
    "#### GRPC Endpoint\n",
    "\n",
    "If you prefer using the GRPC endpoint, the protobuf could be found [here](../onnxruntime/server/protobuf/prediction_service.proto). You could generate your client and make a GRPC call to it. To learn more about how to generate the client code and call to the server, please refer to [the tutorials of GRPC](https://grpc.io/docs/tutorials/).\n",
    "\n",
    "\n",
    "**Note**: Since we currently only support one model, the model name and version can be any string length > 0. In the future, model_names and versions will be verified.\n",
    "\n",
    "### Request and Response Payload\n",
    "\n",
    "The request and response need to be a protobuf message. The Protobuf definition can be found [here](../onnxruntime/server/protobuf/predict.proto).\n",
    "\n",
    "A protobuf message could have two formats: binary and JSON. Usually the binary payload has better latency, in the meanwhile the JSON format is easy for human readability. \n",
    "\n",
    "The HTTP request header field `Content-Type` tells the server how to handle the request and thus it is mandatory for all requests. Requests missing `Content-Type` will be rejected as `400 Bad Request`.\n",
    "\n",
    "* For `\"Content-Type: application/json\"`, the payload will be deserialized as JSON string in UTF-8 format\n",
    "* For `\"Content-Type: application/vnd.google.protobuf\"`, `\"Content-Type: application/x-protobuf\"` or `\"Content-Type: application/octet-stream\"`, the payload will be consumed as protobuf message directly.\n",
    "\n",
    "Clients can control the response type by setting the request with an `Accept` header field and the server will serialize in your desired format. The choices currently available are the same as the `Content-Type` header field. If this field is not set in the request, the server will use the same type as your request.\n",
    "\n",
    "### Inferencing\n",
    "\n",
    "To send a request to the server, you can use any tool which supports making HTTP requests. Here is an example using `curl`:\n",
    "\n",
    "```bash\n",
    "curl -X POST -d \"@predict_request_0.json\" -H \"Content-Type: application/json\" http://127.0.0.1:8001/v1/models/mymodel/versions/3:predict\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "curl -X POST --data-binary \"@predict_request_0.pb\" -H \"Content-Type: application/octet-stream\" -H \"Foo: 1234\"  http://127.0.0.1:8001/v1/models/mymodel/versions/3:predict\n",
    "```\n",
    "\n",
    "### Interactive tutorial notebook\n",
    "\n",
    "A simple Jupyter notebook demonstrating the usage of ONNX Runtime server to host an ONNX model and perform inferencing can be found [here](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxRuntimeServerSSDModel.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Binary Tools for Managing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `saved_model_cli`\n",
    "\n",
    "`run` BNS or gRPC, `convert` to `TensorRT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `scan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T19:33:42.660923Z",
     "start_time": "2020-04-23T19:33:40.942111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: saved_model_cli scan [-h] --dir DIR [--tag_set TAG_SET]\r\n",
      "\r\n",
      "Usage example:\r\n",
      "To scan for blacklisted ops in SavedModel:\r\n",
      "$saved_model_cli scan --dir /tmp/saved_model\r\n",
      "To scan a specific MetaGraph, pass in --tag_set\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help         show this help message and exit\r\n",
      "  --dir DIR          directory containing the SavedModel to execute\r\n",
      "  --tag_set TAG_SET  tag-set of graph in SavedModel to scan, separated by ','\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli scan -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `run`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T19:31:59.149650Z",
     "start_time": "2020-04-23T19:31:57.403530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\r\n",
      "                           SIGNATURE_DEF_KEY [--inputs INPUTS]\r\n",
      "                           [--input_exprs INPUT_EXPRS]\r\n",
      "                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\r\n",
      "                           [--overwrite] [--tf_debug] [--worker WORKER]\r\n",
      "                           [--init_tpu]\r\n",
      "\r\n",
      "Usage example:\r\n",
      "To run input tensors from files through a MetaGraphDef and save the output tensors to files:\r\n",
      "$saved_model_cli show --dir /tmp/saved_model --tag_set serve \\\r\n",
      "   --signature_def serving_default \\\r\n",
      "   --inputs input1_key=/tmp/124.npz[x],input2_key=/tmp/123.npy \\\r\n",
      "   --input_exprs 'input3_key=np.ones(2)' \\\r\n",
      "   --input_examples 'input4_key=[{\"id\":[26],\"weights\":[0.5, 0.5]}]' \\\r\n",
      "   --outdir=/out\r\n",
      "\r\n",
      "For more information about input file format, please see:\r\n",
      "https://www.tensorflow.org/guide/saved_model_cli\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --dir DIR             directory containing the SavedModel to execute\r\n",
      "  --tag_set TAG_SET     tag-set of graph in SavedModel to load, separated by ','\r\n",
      "  --signature_def SIGNATURE_DEF_KEY\r\n",
      "                        key of SignatureDef to run\r\n",
      "  --inputs INPUTS       Loading inputs from files, in the format of '<input_key>=<filename>, or '<input_key>=<filename>[<variable_name>]', separated by ';'. The file format can only be from .npy, .npz or pickle.\r\n",
      "  --input_exprs INPUT_EXPRS\r\n",
      "                        Specifying inputs by python expressions, in the format of \"<input_key>='<python expression>'\", separated by ';'. numpy module is available as 'np'. Will override duplicate input keys from --inputs option.\r\n",
      "  --input_examples INPUT_EXAMPLES\r\n",
      "                        Specifying tf.Example inputs as list of dictionaries. For example: <input_key>=[{feature0:value_list,feature1:value_list}]. Use \";\" to separate input keys. Will override duplicate input keys from --inputs and --input_exprs option.\r\n",
      "  --outdir OUTDIR       if specified, output tensor(s) will be saved to given directory\r\n",
      "  --overwrite           if set, output file will be overwritten if it already exists.\r\n",
      "  --tf_debug            if set, will use TensorFlow Debugger (tfdbg) to watch the intermediate Tensors and runtime GraphDefs while running the SavedModel.\r\n",
      "  --worker WORKER       if specified, a Session will be run on the worker. Valid worker specification is a bns or gRPC path.\r\n",
      "  --init_tpu            if specified, tpu.initialize_system will be called on the Session. This option should be only used if the worker is a TPU job.\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli run -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `convert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T19:30:54.184083Z",
     "start_time": "2020-04-23T19:30:52.454071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: saved_model_cli convert [-h] --dir DIR --output_dir OUTPUT_DIR\r\n",
      "                               --tag_set TAG_SET\r\n",
      "                               {tensorrt} ...\r\n",
      "\r\n",
      "Usage example:\r\n",
      "To convert the SavedModel to one that have TensorRT ops:\r\n",
      "$saved_model_cli convert \\\r\n",
      "   --dir /tmp/saved_model \\\r\n",
      "   --tag_set serve \\\r\n",
      "   --output_dir /tmp/saved_model_trt \\\r\n",
      "   tensorrt \r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --dir DIR             directory containing the SavedModel to convert\r\n",
      "  --output_dir OUTPUT_DIR\r\n",
      "                        output directory for the converted SavedModel\r\n",
      "  --tag_set TAG_SET     tag-set of graph in SavedModel to convert, separated by ','\r\n",
      "\r\n",
      "conversion methods:\r\n",
      "  valid conversion methods\r\n",
      "\r\n",
      "  {tensorrt}            the conversion to run with the SavedModel\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli convert -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Other Tutorials](https://github.com/onnx/tutorials/tree/master/tutorials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx-py37-tf1-15",
   "language": "python",
   "name": "onnx-tf1-15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.016px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
